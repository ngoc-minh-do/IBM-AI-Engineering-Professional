{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Instruction-Tuning with LLMs\n",
    "\n",
    "\n",
    "Instruction-based fine-tuning, referred to as instruction GPT. It trains the language models to follow specific instructions and generate appropriate responses. For instruction-tuning, the dataset plays an important role as it provides structured examples of instructions, contexts, and responses, allowing the model to learn how to handle various tasks effectively. Instruction GPT often uses human feedback to refine and improve model performance; however, this lab doesn't cover this aspect.\n",
    "\n",
    "The context and instruction are concatenated to form a single input sequence that the model can understand and use to generate the correct response.\n",
    "\n",
    "#### Context and instruction\n",
    "\n",
    "\t•\tInstruction: A command to specify what the model should do\n",
    "\t•\tContext: Additional information or background required for performing the instruction\n",
    "\t•\tCombined input: The instruction and context combine together into a single input sequence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review certain examples for various templates:\n",
    "\n",
    "---\n",
    "#### Response template\n",
    "Template: `### Question: {question}\\n ### Answer: {answer}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Question: What is the capital of France?\n",
    "### Answer: Paris\n",
    "```\n",
    "\n",
    "---\n",
    "#### Conversation template\n",
    "\n",
    "Template: `### User: {user_input}\\n ### Bot: {bot_response}`\n",
    "Example:\n",
    "```\n",
    "### User: How are you today?\n",
    "### Bot: I'm doing great, thank you! How can I assist you today?\n",
    "```\n",
    "\n",
    "---\n",
    "#### Instruction and output template\n",
    "\n",
    "Template: `### Instruction: {instruction}\\n ### Output: {output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Instruction: Translate the following sentence to Spanish: \"Hello, how are you?\"\n",
    "### Output: \"Hola, ¿cómo estás?\"\n",
    "```\n",
    "\n",
    "---\n",
    "#### Completion template\n",
    "\n",
    "Template: `{prompt} ### Completion: {completion}`\n",
    "Example:\n",
    "```\n",
    "Once upon a time in a faraway land, ### Completion: there lived a wise old owl who knew all the secrets of the forest.\n",
    "```\n",
    "\n",
    "#### Summarization template\n",
    "\n",
    "Template: `### Text: {text}\\n ### Summary: {summary}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Text: The quick brown fox jumps over the lazy dog.\n",
    "### Summary: A fox jumps over a dog.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Dialogue template\n",
    "\n",
    "Template: `### Speaker 1: {utterance_1}\\n ### Speaker 2: {utterance_2}\\n ### Speaker 1: {utterance_3}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Speaker 1: Hi, what are you doing today?\n",
    "### Speaker 2: I'm going to the park.\n",
    "### Speaker 1: That sounds fun!\n",
    "```\n",
    "\n",
    "---\n",
    "#### Code generation template\n",
    "\n",
    "Template: `### Task: {task_description}\\n ### Code: {code_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Task: Write a function to add two numbers in Python.\n",
    "### Code: def add(a, b):\\n    return a + b\n",
    "```\n",
    "\n",
    "---\n",
    "#### Data analysis template\n",
    "\n",
    "Template: `### Analysis Task: {task_description}\\n ### Analysis: {analysis_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Analysis Task: Provide insights from the sales data of Q1 2022.\n",
    "### Analysis: The sales increased by 15% compared to Q4 2021, with the highest growth in the electronics category.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Recipe template\n",
    "\n",
    "Template: `### Recipe Name: {recipe_name}\\n ### Ingredients: {ingredients}\\n ### Instructions: {instructions}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Recipe Name: Chocolate Chip Cookies\n",
    "### Ingredients: Flour, Sugar, Chocolate Chips, Butter, Eggs, Vanilla Extract\n",
    "### Instructions: Mix the dry ingredients, add the wet ingredients, fold in the chocolate chips, and bake at 350°F for 10-12 minutes.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Explanation template\n",
    "\n",
    "Template: `### Concept: {concept}\\n ### Explanation: {explanation}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Concept: Photosynthesis\n",
    "### Explanation: Photosynthesis is the process by which green plants use sunlight to synthesize nutrients from carbon dioxide and water.\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Understand the various types of templates including instruction-response, question-answering, summarization, code generation, dialogue, data analysis, and explanation and their applications for fine-tuning large language models (LLMs).\n",
    " - Create and apply different templates to fine-tune LLMs for various tasks.\n",
    " - Format datasets based on the created templates to prepare them for effective model training\n",
    " - Perform instruction fine-tuning using Hugging Face libraries and tools\n",
    " - Apply Low-Rank Adaptation (LoRA) techniques to fine-tune LLMs efficiently\n",
    " - Configure and use the SFTTrainer for supervised fine-tuning of instruction-following models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concepts presented in this lab would apply to the other template formats as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Table of contents__\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Install-required-libraries\">Install required libraries</a></li>\n",
    "            <li><a href=\"#Import-required-libraries\">Import required libraries</a></li>\n",
    "            <li><a href=\"#Define-the-device\">Define the device</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Dataset-description\">Dataset description</a></li>\n",
    "    <li><a href=\"#Model-and-tokenizer\">Model and tokenizer</a></li>\n",
    "    <li><a href=\"#Preprocessing-the-data\">Preprocessing the data</a></li>\n",
    "    <li><a href=\"#Test-the-base-model\">Test the base model</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#BLEU-score\">BLEU score</a></li>\n",
    "        </ol>\n",
    "    <li><a href=\"#Perform-instruction-fine-tuning-with-LoRA\">Perform instruction fine-tuning with LoRA</a></li>\n",
    "    <li><a href=\"#Exercises\">Exercises</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Install required libraries\n",
    "\n",
    "For this lab, use the following libraries, which are __not__ preinstalled in the Skills Network Labs environment. You can install libraries by running the code in the below cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user -qq datasets==2.20.0 trl==0.9.6 transformers==4.42.3 peft==0.11.1 tqdm==4.66.4 numpy==1.26.4 pandas==2.2.2 matplotlib==3.9.1 seaborn==0.13.2 scikit-learn==1.5.1 sacrebleu==2.4.2 evaluate==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries\n",
    "\n",
    "The following code imports the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:39:57.464539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743341997.481779    5407 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743341997.487144    5407 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743341997.500330    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743341997.500348    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743341997.500350    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743341997.500352    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 22:39:57.505173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from urllib.request import urlopen\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the device\n",
    "\n",
    "The below code will set your device to 'cuda' if your device is compatible with GPU, otherwise, you can use 'cpu'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "\n",
    "Use the below sentences to download the CodeAlpaca 20k dataset, a programming code dataset. This code is available [here](https://github.com/sahil280114/codealpaca?tab=readme-ov-file#data-release). The CodeAlpaca dataset contains the following elements:\n",
    "\n",
    "\n",
    "- `instruction`: **str**, describes the task the model should perform. Each of the 20K instructions is unique.\n",
    "- `input`: **str**, optional context or input for the task. For example, when the instruction is \"Amend the following SQL query to select distinct elements\", the input is the SQL query. Around 40% of the examples have an input.\n",
    "- `output`: **str**, the answer to the instruction as generated by text-davinci-003.\n",
    "\n",
    "The following code block downloads the CodeAlpaca-20k dataset as a `json` file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-30 22:40:00--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WzOT_CwDALWedTtXjwH7bA/CodeAlpaca-20k.json\n",
      "198.23.119.245ourses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... \n",
      "connected. to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6957007 (6.6M) [application/json]\n",
      "Saving to: ‘CodeAlpaca-20k.json.1’\n",
      "\n",
      "CodeAlpaca-20k.json 100%[===================>]   6.63M   725KB/s    in 10s     \n",
      "\n",
      "2025-03-30 22:40:12 (677 KB/s) - ‘CodeAlpaca-20k.json.1’ saved [6957007/6957007]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WzOT_CwDALWedTtXjwH7bA/CodeAlpaca-20k.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the dataset as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 20022\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"CodeAlpaca-20k.json\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example in the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 's = \"Hello world\" \\ns = s[::-1] \\nprint(s)',\n",
       " 'instruction': 'Reverse the string given in the input',\n",
       " 'input': 'Hello world'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple let's just focus on the examples that do not have any `input`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda example: example[\"input\"] == '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original CodeAlpaca dataset may not have been shuffled. The following line indicates how to shuffle a `datasets.arrow_dataset.Dataset()` object with a random seed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 9764\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CodeAlpaca 20k dataset has a training and test set. You can split the original training data into a train and test set by assigning 80% of the data to the training set and 20% to the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input'],\n",
       "        num_rows: 7811\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'instruction', 'input'],\n",
       "        num_rows: 1953\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset_split['train']\n",
    "test_dataset = dataset_split['test']\n",
    "dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small set of data for the resource limitation\n",
    "# This dataset will be only used for evaluation parts, not for the training\n",
    "tiny_test_dataset=test_dataset.select(range(10))\n",
    "tiny_train_dataset=train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and tokenizer\n",
    "\n",
    "In this exercise, let's fine-tune the [`opt-350m`](https://huggingface.co/facebook/opt-350m) model from Facebook. A description of this OpenSource model was published [here](https://arxiv.org/abs/2205.01068), and the model was originally made available on [metaseq's Github repository](https://github.com/facebookresearch/metaseq).\n",
    "\n",
    "The below lines load the base model from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model comes with its own tokenizer which you will be loading here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\", padding_side='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the end of sentence (EOS) token. This is a special tokenizer token. Once this token is encountered, the model will stop generating further tokens:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "To perform the fine-tuning, first, preprocess the data by creating functions that generate the prompt.\n",
    "\n",
    "The `formatting_prompts_func` function takes a dataset as input. For every element in the dataset format, the instruction and the output into a template using the format:\n",
    "\n",
    "```\n",
    "### Instruction:\n",
    "Translate the following sentence to Spanish: \"Hello, how are you?\"\n",
    "\n",
    "### Response:\n",
    "\"Hola, ¿cómo estás?</s>\"\n",
    "```\n",
    "\n",
    "_**Note:**_ \n",
    "1. The template provided in this section may differ from the **Instruction and output template** presented in the introduction of this lab. You can replace the  `### Response:` with `### Output:` to generate similar results.\n",
    "\n",
    "2. Introducing the `</s>` end of sentence token at the end of the text informs the model to stop generating text beyond this point.\n",
    "\n",
    "Finally, the `formatting_prompts_func_no_response` function behaves similarly to the `formatting_prompts_func` except the response is not included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Instruction:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Response:\\n{mydataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "def formatting_prompts_func_no_response(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Instruction:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Response:\\n\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates the `instructions` (the part of the prompt that does not include the response), the `instructions_with_responses` (the full prompt with the response and `eos` token), and the `expected_outputs`, which are the parts of the `instructions_with_responses` that are between the `instructions` and the `eos` token.\n",
    "\n",
    "To find the `expected_outputs`, tokenize `instructions` and the `instructions_with_responses`. Then, count the number of tokens in `instructions`, and discard the equivalent amount of tokens from the beginning of the tokenized `instructions_with_responses` vector. Finally, discard the final token in `instructions_with_responses`, corresponding to the `eos` token. Decode the resulting vector using the tokenizer, resulting in the `expected_output`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 1953/1953 [00:01<00:00, 1636.11it/s]\n"
     ]
    }
   ],
   "source": [
    "expected_outputs = []\n",
    "instructions_with_responses = formatting_prompts_func(test_dataset)\n",
    "instructions = formatting_prompts_func_no_response(test_dataset)\n",
    "for i in tqdm(range(len(instructions_with_responses))):\n",
    "    tokenized_instruction_with_response = tokenizer(instructions_with_responses[i], return_tensors=\"pt\", max_length=1024, truncation=True, padding=False)\n",
    "    tokenized_instruction = tokenizer(instructions[i], return_tensors=\"pt\")\n",
    "    expected_output = tokenizer.decode(tokenized_instruction_with_response['input_ids'][0][len(tokenized_instruction['input_ids'][0])-1:], skip_special_tokens=True)\n",
    "    expected_outputs.append(expected_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example to view what `instructions` include, `instructions_with_responses`, and `expected_outputs`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## instructions ##############\n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "### Response:\n",
      "\n",
      "############## instructions_with_responses ##############\n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "### Response:\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.</s>\n",
      "\n",
      "############## expected_outputs ##############\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.\n"
     ]
    }
   ],
   "source": [
    "print('############## instructions ##############\\n' + instructions[0])\n",
    "print('############## instructions_with_responses ##############\\n' + instructions_with_responses[0])\n",
    "print('\\n############## expected_outputs ##############' + expected_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of keeping the instructions as-is, it's beneficial to convert the `instructions` list into a `torch` `Dataset`. The following code defines a class called `ListDataset` that inherits from `Dataset` and creates a `torch` `Dataset` from a list. This class is then used to generate a `Dataset` object from `instructions`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListDataset(Dataset):\n",
    "    def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.original_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.original_list[i]\n",
    "\n",
    "instructions_torch = ListDataset(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction:\\nName the most important benefit of using a database system.\\n\\n### Response:\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions_torch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the base model\n",
    "\n",
    "Let's understand how the base model performs without performing fine-tuning in the model. This may involve response generation from the base, that is from the non-fine-tuned mode. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code defines a text generation pipeline using the `pipeline` class from `transformers`. This pipeline is useful to generate text given by a model and a tokenizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "gen_pipeline = pipeline(\"text-generation\",\n",
    "                        model=model,\n",
    "                        tokenizer=tokenizer,\n",
    "                        device=device,\n",
    "                        batch_size=2,\n",
    "                        max_length=50,\n",
    "                        truncation=True,\n",
    "                        padding=False,\n",
    "                        return_full_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** The generation pipeline can generate tokens or text. If```return_tensors=True```, the pipeline returns token IDs; otherwise, it returns words. Additionally, the generation pipeline generates both the instructions *and* the responses by default. However, to assess the model's performance, exclude the generated instructions and focus on the responses. To do this, set ```return_full_text=False```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code leverages the pre-defined generation pipeline to generate outputs using the model. \n",
    "\n",
    "**_Note:_** The code is commented out because it may take a long time for CPU. Instead of generating the raw tokens here, you can load output from this model later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Due to resource limitation, only apply the function on 3 records using \"instructions_torch[:10]\"\n",
    "    pipeline_iterator= gen_pipeline(instructions_torch[:3], \n",
    "                                    max_length=50, # this is set to 50 due to resource constraint, using a GPU, you can increase it to the length of your choice\n",
    "                                    num_beams=5,\n",
    "                                    early_stopping=True,)\n",
    "\n",
    "generated_outputs_base = []\n",
    "for text in pipeline_iterator:\n",
    "    generated_outputs_base.append(text[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code loads the generated responses for the whole dataset using machine that has access to a fast CUDA-enabled GPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VvQRrSqS1P0_GobqtL-SKA/instruction-tuning-generated-outputs-base.pkl')\n",
    "generated_outputs_base = pickle.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the sample responses generated by the base model and the expected responses from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Come up with a Java program that checks if one string is a substring of another.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "public static boolean isSubstring(String s, String x) {\n",
      "    int i = 0, j = 0;\n",
      "    while (i < s.length() && j < x.length()) {\n",
      "        if (s.charAt(i) == x.charAt(j)) {\n",
      "            i++;\n",
      "            j++;\n",
      "        } else {\n",
      "            i = i - j + 1;\n",
      "            j = 0;\n",
      "        }\n",
      "    }\n",
      "    if (j == x.length()) {\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      "list.pop()\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_base[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the responses generated by the base model are not up to the mark. Also, the responses have the tendency to extend and repeat the answers until they generate the maximum number of tokens. Later on, you can see that the instruction-tuning can fix both of these issues. First, the instruction fine-tuned model will be able to provide more meaningful responses. Second, because, you appended the `eos` token `<\\s>` to the output, you will teach the model via instruction fine-tuning to not generate responses without bound.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU score\n",
    "\n",
    "Let's set up a metric that compares the generated responses and the expected responses in the test environment. In this lab, let's use the [BLEU score](https://en.wikipedia.org/wiki/BLEU), a metric originally intended to check the quality of translations made by translation models. You can calculate the BLEU scores for individual generated segments by comparing them with a set of expected outputs and average the scores for the individual segments. Depending on the implementation, BLEU scores range from 0 to 1 or from 0 to 100 (as in the implementation used herein), with higher scores indicating a better match between the model generated output and the expected output.\n",
    "\n",
    "_**Note:**_ \n",
    "1. The BLEU score was originally implemented for assessing the quality of translations. However, it may not necessarily be the best metric for instruction fine-tuning in general, but it is nonetheless a useful metric that gives a sense of the alignment between the model generated output and the expected output.\n",
    "2. BLEU scores are very challenging to compare from one study to the next because it is a parametrized metric. As a result, you can employ a variant of BLEU called [SacreBLEU](https://aclanthology.org/W18-6319/) invariant to the metric's parametrization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_base = sacrebleu.compute(predictions=generated_outputs_base,\n",
    "                                 references=expected_outputs)\n",
    "\n",
    "print(list(results_base.keys()))\n",
    "print(round(results_base[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low SacreBLEU score indicates that there is very little alignment between the base model's generated responses and the expected responses for the examples in the test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform instruction fine-tuning with LoRA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, let's perform instruction fine-tuning using a parameter-efficient fine-tuning (PEFT) method called low-rank adaptation (LoRA).\n",
    "First, convert the model into a PEFT model suitable for LoRA fine-tuning by defining a `LoraConfig` object from the `peft` library that outlines LoRA parameters, such as the LoRA rank and the target modules. Next, apply LoRA configuration on the model using `get_peft_model()`, which effectively converts `model` into a LoRA `model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,  # Low-rank dimension\n",
    "    lora_alpha=32,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate\n",
    "    task_type=TaskType.CAUSAL_LM  # Task type should be causal language model\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction fine-tuning using the `SFTTrainer` has the effect of generating the instructions *and* the responses. However, for the purposes of assessing the quality of the generated text, consider only the quality of the response and not the quality of the instruction. For the purposes of calculating the BLEU score, eliminate the length of tokens corresponding to the instruction from the beginning of the tokenized model output. \n",
    "\n",
    "For example, suppose the tokenized instruction had a length of ten, but the generated text had a length of fourteen. Then the tokenized response that was kept for the purposes of calculating the BLEU score was just the four tokens at the end of the tokenized generated text because the first ten tokens represent the model's generation of the tokenized instruction.\n",
    "\n",
    "Although eliminating the first few tokens of the tokenized output worked well for the purposes of calculating BLEU. However, during fine-tuning, the first few tokens won't have an impact on the loss function. You can mask those tokens using -100 by ignoring the value of PyTorch loss functions such as [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). By masking the tokens corresponding to the instruction with -100, only the tokens associated with the response can bear the loss.\n",
    "\n",
    "You can create such a masking manually by defining your own function. However, it is easier to instead use the `DataCollatorForCompletionOnlyLM` class from `trl`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template = \"### Response:\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pass the `collator`, `DataCollatorForCompletionOnlyLM` object to the data collator into `SFTTrainer`, resulting in the generated instructions without bearing on the loss.\n",
    "\n",
    "To perform the training, first configure our `SFTTrainer`, and create the `SFTTrainer` object by passing to the `collator`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m SFTConfig(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     do_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# eval_dataset=test_dataset,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatting_prompts_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:194\u001b[0m, in \u001b[0;36mSFTTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    192\u001b[0m preprocess_dataset \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdataset_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_prepare_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess_dataset:\n\u001b[0;32m--> 194\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpacking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m         packing \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpacking \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_packing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_packing\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:413\u001b[0m, in \u001b[0;36mSFTTrainer._prepare_dataset\u001b[0;34m(self, dataset, processing_class, args, packing, formatting_func, dataset_name)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, Dataset):  \u001b[38;5;66;03m# `IterableDataset.map` does not support `desc`\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     map_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying formatting function to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 413\u001b[0m batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mformatting_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_func\u001b[39m(example):\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: formatting_func(example)}\n",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m, in \u001b[0;36mformatting_prompts_func\u001b[0;34m(mydataset)\u001b[0m\n\u001b[1;32m      2\u001b[0m output_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mydataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m      4\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Instruction:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmydataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Response:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmydataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     output_texts\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_texts\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    packing=False,\n",
    "    per_device_train_batch_size=2,  # Reduce batch size\n",
    "    per_device_eval_batch_size=2,  # Reduce batch size\n",
    "    max_seq_length=1024,\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please ignore the above warning.\n",
    "The below comments, runs the trainer, because this would take a long time on the CPU. Therefore, let's not run the trainer here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train the trainer, the `trainer` object would have a state history for every training step. You would be able to access this state history using the below commented out line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_history_lora = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of extracting the state history above, let's load the state history of a model that was instruction fine-tuned to the above specifications on a GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/49I70jQD0-RNRg2v-eOoxg/instruction-tuning-log-history-lora.json')\n",
    "log_history_lora = json.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the training loss for each training step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = [log[\"loss\"] for log in log_history_lora if \"loss\" in log]\n",
    "\n",
    "# Plot the training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to fine-tune the model, the fine-tuned model could be saved using the below commented out line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"./instruction_tuning_final_model_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine the text generation pipeline because the model has been changed to the LoRA model. Ignore the warning for the `PeftModelForCausalLM` not being supported for `text-generation`. However, if the PEFT model is supported, the warning is erroneous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "gen_pipeline = pipeline(\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        device=device, \n",
    "                        batch_size=2, \n",
    "                        max_length=50, \n",
    "                        truncation=True, \n",
    "                        padding=False,\n",
    "                        return_full_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code generates tokens with the pipeline using the instruction fine-tuned model. Only three records of data are used for demonstration  because generating text is time consuming on CPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Due to resource limitation, only apply the function on 3 records using \"instructions_torch[:10]\"\n",
    "    pipeline_iterator= gen_pipeline(instructions_torch[:3],\n",
    "                                max_length=50, # this is set to 50 due to resource constraint, using a GPU, you can increase it to the length of your choice\n",
    "                                num_beams=5,\n",
    "                                early_stopping=True,)\n",
    "generated_outputs_lora = []\n",
    "for text in pipeline_iterator:\n",
    "    generated_outputs_lora.append(text[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### Instruction:\\nName the most important benefit of using a database system.\\n\\n### Response:'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_outputs_lora[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the generated texts for the entire dataset from the fine-tuned LoRA model and run on GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/o7uYxe15xvX4CN-6Lr10iA/instruction-tuning-generated-outputs-lora.pkl')\n",
    "generated_outputs_lora = pickle.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some of the responses from the instruction fine-tuned model and the expected responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "Name the most important benefit of using a database system.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "The most important benefit of using a database system is the ability to store and retrieve data quickly and easily. Database systems also provide support for data security, data integrity, and concurrently accessing and modifying data from multiple systems.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "The type of data structure to use to store key-value pairs in a Python program would be a key-value pair.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Come up with a Java program that checks if one string is a substring of another.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "public static boolean isSubstring(String s, String x) {\n",
      "    int i = 0, j = 0;\n",
      "    while (i < s.length() && j < x.length()) {\n",
      "        if (s.charAt(i) == x.charAt(j)) {\n",
      "            i++;\n",
      "            j++;\n",
      "        } else {\n",
      "            i = i - j + 1;\n",
      "            j = 0;\n",
      "        }\n",
      "    }\n",
      "    if (j == x.length()) {\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "\n",
      "A method to solve an equation of the form ax + b = 0 is:\n",
      "\n",
      "def solve(x, y):\n",
      "    return x * y\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "How do you remove the last item from a list in Python?\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      "list.pop()\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      ".big-header {\n",
      "    text-size: 24px;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_lora[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the base model, you can see that the responses are much better. Additionally, the responses don't extend until the maximum number of tokens are generated.\n",
    "\n",
    "To confirm the responses generated by the instruction fine-tuned model align better with the expected output, let's calculate the SacreBLEU score:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "1.2\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_lora = sacrebleu.compute(predictions=generated_outputs_lora,\n",
    "                                 references=expected_outputs)\n",
    "print(list(results_lora.keys()))\n",
    "print(round(results_lora[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the fine-tuned model achieves SacreBLEU score which is significantly better than the one achieved by the base model. \n",
    "\n",
    "Let's conclude. The instruction fine-tuned model generates responses that align much better with the expected responses in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Try with another response template (Question-Answering)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `formatting_prompts_response_template` function to format the train_dataset in the Response Template. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template: `### Question: {question}\\n ### Answer: {answer}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "def formatting_prompts_response_template(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n{mydataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "def formatting_prompts_response_template(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n{mydataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `formatting_prompts_response_template_no_response` function to format the `test_dataset` in the Response Template, excluding the response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template: `### Question: {question}\\n ### Answer: `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "def formatting_prompts_response_template_no_response(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "def formatting_prompts_response_template_no_response(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Try with another LLM (EleutherAI/gpt-neo-125m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EleutherAI/gpt-neo-125m is a smaller variant of the GPT-Neo family of models developed by EleutherAI. With 125 million parameters, it is designed to be computationally efficient while still providing robust performance for various natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the `EleutherAI/gpt-neo-125m` model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e9046c4a-74a3-43e2-a49c-17bec608ffcc)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/util/retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:367\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the model and tokenizer\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:944\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m         )\n\u001b[0;32m--> 944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2008\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2006\u001b[0m             resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m download_url(file_path, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m   2007\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2008\u001b[0m         resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2010\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2011\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2012\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2013\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2014\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2015\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2016\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2018\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2019\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2025\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unresolved_files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:342\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    357\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    844\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1011\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1009\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1011\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1022\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1547\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1545\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1547\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1556\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1557\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:371\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    369\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _adjust_range_header(headers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m), resume_size)\n\u001b[0;32m--> 371\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m    375\u001b[0m content_length \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:303\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/workspace/IBM-AI-Engineering-Professional/.venv/lib/python3.12/site-packages/requests/adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e9046c4a-74a3-43e2-a49c-17bec608ffcc)')"
     ]
    }
   ],
   "source": [
    "#write your code here\n",
    "model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LoRA Configuration:\n",
    "\n",
    "- r: 8 (Low-rank dimension)\n",
    "- lora_alpha: 16 (Scaling factor)\n",
    "- target_modules: [\"q_proj\", \"v_proj\"] (Modules to apply LoRA)\n",
    "- lora_dropout: 0.1 (Dropout rate)\n",
    "- task_type: TaskType.CAUSAL_LM (Task type should be causal language model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Low-rank dimension\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate\n",
    "    task_type=TaskType.CAUSAL_LM  # Task type should be causal language model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Low-rank dimension\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate\n",
    "    task_type=TaskType.CAUSAL_LM  # Task type should be causal language model\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply LoRA Configuration to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "model = get_peft_model(model, lora_config)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wojciech \"Victor\" Fulmyk](https://www.linkedin.com/in/wfulmyk) is a Data Scientist and a PhD Candidate in Economics at the University of Calgary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fateme Akbari](https://www.linkedin.com/in/fatemeakbari/) is a Ph.D. candidate in Information Systems at McMaster University with demonstrated research experience in Machine Learning and NLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo) has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/main/en/sft_trainer)\n",
    "\n",
    "[Finetuning To Follow Instructions](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/ch07.ipynb)\n",
    "\n",
    "[Finetuning with LoRA -- A Hands-On Example](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{## Change Log|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2024-07-18|1.0|Wojciech \"Victor\" Fulmyk|Lab Written||2024-07-25|2.0|Fateme Akbari|Bugs Fixed||2024-07-31|3.0|Bhavika Chhatbar|ID reviewed|}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "193b491dbb3af9428b95c141e897c5ad06433b61b2a80b8b5bbc25b3b509c143"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
