{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726978d1-1697-42ce-b15a-d1eb5435e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# #After executing the cell,please RESTART the kernel and run all the cells.\n",
    "# !pip install --user \"ibm-watsonx-ai==1.0.10\"\n",
    "# !pip install --user \"langchain==0.2.6\" \n",
    "# !pip install --user \"langchain-ibm==0.1.8\"\n",
    "# !pip install --user \"langchain-community==0.2.1\"\n",
    "# !pip install --user pypdf\n",
    "# !pip install --user chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda284dd-0ae9-4657-a8b6-3d9b8cd8da94",
   "metadata": {},
   "source": [
    "## Task 1: Load document using LangChain for different sources (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "636ae9b3-200b-4add-aefa-a3ed4506945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Comprehensive Review of Low-Rank\n",
      "Adaptation in Large Language Models for\n",
      "Efficient Parameter Tuning\n",
      "September 10, 2024\n",
      "Abstract\n",
      "Natural Language Processing (NLP) often involves pre-training large\n",
      "models on extensive datasets and then adapting them for specific tasks\n",
      "through fine-tuning. However, as these models grow larger, like GPT-3\n",
      "with 175 billion parameters, fully fine-tuning them becomes computa-\n",
      "tionally expensive. We propose a novel method called LoRA (Low-Rank\n",
      "Adaptation) that significantly reduces the overhead by freezing the orig-\n",
      "inal model weights and only training small rank decomposition matrices.\n",
      "This leads to up to 10,000 times fewer trainable parameters and reduces\n",
      "GPU memory usage by three times. LoRA not only maintains but some-\n",
      "times surpasses fine-tuning performance on models like RoBERTa, De-\n",
      "BERTa, GPT-2, and GPT-3. Unlike other methods, LoRA introduces\n",
      "no extra latency during inference, making it more efficient for practical\n",
      "applications. All relevant code an\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WgM1DaUn2SYPcCg_It57tA/A-Comprehensive-Review-of-Low-Rank-Adaptation-in-Large-Language-Models-for-Efficient-Parameter-Tuning-1.pdf\"\n",
    "loader = PyPDFLoader(pdf_url)\n",
    "pages = loader. load_and_split()\n",
    "\n",
    "full_content = ''.join([page.page_content for page in pages])\n",
    "\n",
    "print(full_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a4b81-2ae2-4c4b-a777-469ccdc98d34",
   "metadata": {},
   "source": [
    "## Task 2: Apply text splitting techniques (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a36bac-957a-4388-9b63-98a14541db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_6344/4152479243.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  latex_text = \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='\\\\documentclass{article}\\n    \\n    \\x08egin{document}'),\n",
       " Document(metadata={}, page_content='\\\\maketitle\\n    \\n    \\\\section{Introduction}\\n    Large'),\n",
       " Document(metadata={}, page_content='language models (LLMs) are a type of machine learning model'),\n",
       " Document(metadata={}, page_content='that can be trained on vast amounts of text data to'),\n",
       " Document(metadata={}, page_content='generate human-like language. In recent years, LLMs have'),\n",
       " Document(metadata={}, page_content='made significant advances in a variety of natural language'),\n",
       " Document(metadata={}, page_content='processing tasks, including language translation, text'),\n",
       " Document(metadata={}, page_content='generation, and sentiment analysis.'),\n",
       " Document(metadata={}, page_content='\\\\subsection{History of LLMs}\\n    The earliest LLMs were'),\n",
       " Document(metadata={}, page_content='developed in the 1980s and 1990s, but they were limited by'),\n",
       " Document(metadata={}, page_content='the amount of data that could be processed and the'),\n",
       " Document(metadata={}, page_content='computational power available at the time. In the past'),\n",
       " Document(metadata={}, page_content='decade, however, advances in hardware and software have'),\n",
       " Document(metadata={}, page_content='made it possible to train LLMs on massive datasets, leading'),\n",
       " Document(metadata={}, page_content='to significant improvements in performance.'),\n",
       " Document(metadata={}, page_content='\\\\subsection{Applications of LLMs}\\n    LLMs have many'),\n",
       " Document(metadata={}, page_content='applications in industry, including chatbots, content'),\n",
       " Document(metadata={}, page_content='creation, and virtual assistants. They can also be used in'),\n",
       " Document(metadata={}, page_content='academia for research in linguistics, psychology, and'),\n",
       " Document(metadata={}, page_content='computational linguistics.\\n    \\n    \\\\end{document}')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "latex_text = \"\"\"\n",
    "    \\documentclass{article}\n",
    "    \n",
    "    \\begin{document}\n",
    "    \n",
    "    \\maketitle\n",
    "    \n",
    "    \\section{Introduction}\n",
    "    Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in a variety of natural language processing tasks, including language translation, text generation, and sentiment analysis.\n",
    "    \n",
    "    \\subsection{History of LLMs}\n",
    "    The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.\n",
    "    \n",
    "    \\subsection{Applications of LLMs}\n",
    "    LLMs have many applications in industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\n",
    "    \n",
    "    \\end{document}\n",
    "\"\"\"\n",
    "\n",
    "latex_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.LATEX, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "latex_docs = latex_splitter.create_documents([latex_text])\n",
    "latex_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db40c0b-3abf-42dc-baa0-eae4f35e1ea0",
   "metadata": {},
   "source": [
    "## Task 3: Embed documents (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97cac22d-cca4-40b5-bf94-ec8c39dff923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.018171897, -0.018608226, 0.059054308, 0.07260351, 0.08736516]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "\n",
    "embed_params = {\n",
    "    EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "    EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "}\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/slate-30m-english-rtrvr\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id=\"skills-network\",\n",
    "    params=embed_params,\n",
    ")\n",
    "\n",
    "query = \"How are you?\"\n",
    "query_result = watsonx_embedding.embed_documents([query])\n",
    "\n",
    "query_result[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21037967-f87a-4ffa-80c1-9324c3ea190b",
   "metadata": {},
   "source": [
    "## Task 4: Create and configure vector databases to store embeddings (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f645a0-a0b0-4a35-905f-b551ee65f048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-06 08:35:38--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 6363 (6.2K) [text/plain]\n",
      "Saving to: ‘new-Policies.txt.5’\n",
      "\n",
      "new-Policies.txt.5  100%[===================>]   6.21K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-04-06 08:35:38 (704 MB/s) - ‘new-Policies.txt.5’ saved [6363/6363]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy promotes the safe and responsible use of digital communication tools in line with our'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy promotes the safe and responsible use of digital communication tools in line with our'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy lays the foundation for a diverse, inclusive, and talented workforce. It ensures that')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\"\n",
    "loader = TextLoader(\"new-Policies.txt\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "vectordb = Chroma.from_documents(chunks, watsonx_embedding)\n",
    "\n",
    "query = \"Smoking policy\"\n",
    "docs = vectordb.similarity_search(query, k=5)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f84ec-75d1-4df9-b6e7-28c949e7723d",
   "metadata": {},
   "source": [
    "## Task 5: Develop a retriever to fetch document segments based on queries (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef2d65b-ae6e-4dda-8d45-5b72e87eb495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'new-Policies.txt'}, page_content='and email use, including copyright and data protection laws.'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "query = \"Email policy\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec800263-38f7-4a3a-ab51-05fdafa92c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0f7c0-46d6-451a-8806-99edc0fee7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
