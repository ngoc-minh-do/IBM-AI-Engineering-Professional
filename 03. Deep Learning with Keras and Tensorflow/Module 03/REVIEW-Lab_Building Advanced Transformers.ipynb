{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m829.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.68.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.8/391.8 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.28.3 pyarrow-18.0.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m36.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 00:11:52.907637: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-26 00:11:52.909910: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-26 00:11:52.913976: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-26 00:11:52.926293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732579912.947256      82 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732579912.953181      82 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-26 00:11:52.975224: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 00:11:55.594876: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - loss: 12.5093\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.2509\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1986\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1664\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1816\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1357\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1356\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.2090\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0880\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1706\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0889\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1045\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1048\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0963\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1202\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0726\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0629\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0592\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0480\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2dd06fcd50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 319ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - loss: 6.1340\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 1.3914\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.8199\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.4298\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.2294\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1404\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1069\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0517\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0269\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0222\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0206\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0244\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0232\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0197\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0205\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0177\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0204\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0173\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0146\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0111\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 308ms/step - loss: 0.0013\n",
      "Test loss: 0.0018796366639435291\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Add a dropout layer after the Flatten layer\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
    "dropout = Dropout(0.5)(flatten)\n",
    "outputs = tf.keras.layers.Dense(1)(dropout)\n",
    " \n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    " \n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    " \n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    " \n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 616ms/step - loss: 0.0186\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 614ms/step - loss: 0.0402\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 613ms/step - loss: 0.0353\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 616ms/step - loss: 0.0600\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 616ms/step - loss: 0.0241\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 610ms/step - loss: 0.0147\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 608ms/step - loss: 0.0210\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 609ms/step - loss: 0.0207\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 615ms/step - loss: 0.0202\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 614ms/step - loss: 0.0119\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 611ms/step - loss: 0.0130\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 613ms/step - loss: 0.0140\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 614ms/step - loss: 0.0124\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 618ms/step - loss: 0.0187\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 615ms/step - loss: 0.0125\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 610ms/step - loss: 0.0112\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 606ms/step - loss: 0.0093\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 606ms/step - loss: 0.0088\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 608ms/step - loss: 0.0103\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 610ms/step - loss: 0.0146\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 304ms/step - loss: 0.0022\n",
      "Test loss with batch size 16: 0.004690260160714388\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0081\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 0.0050\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0032\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0029\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0029\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0028\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0026\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0025\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0026\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0030\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0024\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 0.0025\n",
      "Epoch 13/20\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 2s/step - loss: 0.0028"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
